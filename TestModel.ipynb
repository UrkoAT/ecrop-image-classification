{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from patchify import patchify\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "PATCH_SIZE = 480\n",
    "\n",
    "def patch_image(image):\n",
    "\n",
    "    instances = []\n",
    "\n",
    "    if type(image) == str:\n",
    "        image = cv2.imread(image)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    size_x = (image.shape[1] // PATCH_SIZE) * PATCH_SIZE  # get width to nearest size divisible by patch size\n",
    "    size_y = (image.shape[0] // PATCH_SIZE) * PATCH_SIZE  # get height to nearest size divisible by patch size\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Crop original image to size divisible by patch size from top left corner\n",
    "    image = np.array(image.crop((0, 0, size_x, size_y)))\n",
    "\n",
    "    # Extract patches from each image, step=patch_size means no overlap\n",
    "    patch_img = patchify(image, (PATCH_SIZE, PATCH_SIZE, 3), step=PATCH_SIZE)\n",
    "\n",
    "    # iterate over vertical patch axis\n",
    "    for j in range(patch_img.shape[0]):\n",
    "        # iterate over horizontal patch axis\n",
    "        for k in range(patch_img.shape[1]):\n",
    "            # patches are located like a grid. use (j, k) indices to extract single patched image\n",
    "            single_patch_img = patch_img[j, k]\n",
    "\n",
    "            # Drop extra extra dimension from patchify\n",
    "            instances.append(np.squeeze(single_patch_img))\n",
    "\n",
    "    return instances, (int(size_x/PATCH_SIZE), int(size_y/PATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    img = Image.fromarray(image)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depatchify(patches_arr, size, p_size=PATCH_SIZE):\n",
    "    patches_np = np.array(patches_arr)\n",
    "\n",
    "    w, h = size\n",
    "\n",
    "    reshaped = patches_np.reshape(w, h, p_size, p_size, 3)\n",
    "\n",
    "    bag = []\n",
    "\n",
    "    for subindex in range(reshaped.shape[0]):\n",
    "        line = np.concatenate(reshaped[subindex],axis=1)\n",
    "        bag.append(line)\n",
    "\n",
    "    image_to_reshape = np.array(bag)\n",
    "\n",
    "\n",
    "\n",
    "    return image_to_reshape.reshape(w*p_size, h*p_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class MaskColorMap(Enum):\n",
    "    Urban = (0, 255, 255) # Cyan\n",
    "    Agriculture = (255, 255, 0) # Amarillo\n",
    "    Rangeland = (255, 0, 255) # Morado\n",
    "    Forest = (0, 255, 0) # Verde\n",
    "    Water = (0, 0, 255) # Azul\n",
    "    Barren = (255, 255, 255) # Blanco\n",
    "    Uknown = (0,0,0) # Negro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import flatten, sum\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (sum(y_true_f) + sum(y_pred_f) - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_encode_mask(mask):\n",
    "    # initialize rgb image with equal spatial resolution\n",
    "    rgb_encode_image = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    # iterate over MaskColorMap\n",
    "    for j, cls in enumerate(MaskColorMap):\n",
    "        # convert single integer channel to RGB channels\n",
    "        rgb_encode_image[(mask == j)] = np.array(cls.value) / 255.\n",
    "    return rgb_encode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('new_model_escrop_solo_0.h5', custom_objects={'jaccard_index': jaccard_index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, size = patch_image('dataset/11/train/28689_sat.jpg')\n",
    "groundtruth_bgr = cv2.imread('dataset/11/masks/28689_mask.png')\n",
    "groundtruth = cv2.cvtColor(groundtruth_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(depatchify(patches, size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for patch in patches:\n",
    "    pred = model.predict(np.expand_dims(patch, 0))\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    pred = rgb_encode_mask(pred)\n",
    "    pred = pred*255\n",
    "    predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = depatchify(predictions, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array(predictions, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = depatchify(p, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5873b2ce1d0814eeeaf9049717a39c9e63ca0e9502b50f2615166b10c5e24a4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
